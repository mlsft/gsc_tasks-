{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_CERN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_vwS8EuMXpf",
        "colab_type": "code",
        "outputId": "d84c1e9c-bd05-497e-bc83-4a69dd7a6dda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKwcQyL4MveT",
        "colab_type": "code",
        "outputId": "c6b66fcd-d3fc-4415-e988-cc2c4bfa6c9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd drive/My Drive/google_colab_gpu/GSOC 2020/CERN-HSF"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/google_colab_gpu/GSOC 2020/CERN-HSF\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xamQoa6MyCL",
        "colab_type": "code",
        "outputId": "08597193-5cf7-4017-b3fb-b641af7b3088",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keras_CERN.ipynb  Pytorch_CERN.ipynb\n",
            "model1.h5         SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\n",
            "model2.h5         SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAJwDZZ5M1s_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab.patches import cv2_imshow\n",
        "import h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHtiqY7dM5X_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import cv2\n",
        "#from keras.datasets import mnist\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential,load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0fpdKirNGcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename='SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5'\n",
        "data1 = h5py.File(filename, 'r')\n",
        "Y1=data1['y']\n",
        "X1=data1['X']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lQ70KxKwqTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename='SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5'\n",
        "data0 = h5py.File(filename, 'r')\n",
        "Y0=data0['y']\n",
        "X0=data0['X']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOdcssMIxycN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_final=np.concatenate((X0[:],X1[:]),axis=0)\n",
        "Y_final=np.concatenate((Y0[:],Y1[:]),axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPMoSgQTx7yE",
        "colab_type": "code",
        "outputId": "e89e4d4b-2c92-49f2-ae3b-e3a2d13f807d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train,X_valid, Y_train, Y_valid = train_test_split(X_final,Y_final,test_size = 0.2, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_valid.shape,Y_valid.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(398400, 32, 32, 2) (398400,)\n",
            "(99600, 32, 32, 2) (99600,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qshJ_-TBx-E1",
        "colab_type": "code",
        "outputId": "28c68d7e-6cd2-4b56-b410-8f1273c12cfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "X_train0=(X_train[:,:,:,0].reshape((X_train.shape[0],1,X_train.shape[1],X_train.shape[2])))\n",
        "X_valid0=(X_valid[:,:,:,0].reshape((X_valid.shape[0],1,X_valid.shape[1],X_valid.shape[2])))\n",
        "X_train1=(X_train[:,:,:,1].reshape((X_train.shape[0],1,X_train.shape[1],X_train.shape[2])))\n",
        "X_valid1=(X_valid[:,:,:,1].reshape((X_valid.shape[0],1,X_valid.shape[1],X_valid.shape[2])))\n",
        "X_train.shape,X_valid.shape,X_train0.shape,X_valid0.shape,X_train1.shape,X_valid1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((398400, 32, 32, 2),\n",
              " (99600, 32, 32, 2),\n",
              " (398400, 1, 32, 32),\n",
              " (99600, 1, 32, 32),\n",
              " (398400, 1, 32, 32),\n",
              " (99600, 1, 32, 32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRNCTQm0yWb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train0, Y_train, X_valid0, Y_valid, X_train1, X_valid1 = map(torch.tensor, (X_train0, Y_train_tp, X_valid0, Y_valid_tp, X_train1, X_valid1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxFk2U7082yF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils import data\n",
        "\n",
        "class Dataset(data.Dataset):\n",
        "  'Characterizes a dataset for PyTorch'\n",
        "  def __init__(self, inputs, labels):\n",
        "        'Initialization'\n",
        "        self.labels = labels\n",
        "        self.inputs = inputs\n",
        "\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.inputs)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "\n",
        "        # Get data and get label\n",
        "        X = self.inputs[index]\n",
        "        y = self.labels[index]\n",
        "\n",
        "        return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4neJCXuq0xwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset={'input':X_train0,'output':Y_train},\n",
        "                                          batch_size=1024,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset={'input':X_valid0},\n",
        "                                          batch_size=1024,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDCVvPtIyNWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "window_height=32\n",
        "window_width=32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOMx04EDwqi1",
        "colab_type": "code",
        "outputId": "b62b2608-95ad-4d98-9e46-f21eb4b4df94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        #self.relu1 = nn.Relu()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        #self.relu2 = nn.Relu()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(32*8*8, 128)\n",
        "        #self.relu3 = nn.Relu()\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        #self.relu4 = nn.Relu()\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "        #self.sigmoid1 = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.sigmoid(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net.cuda()\n",
        "summary(net, (1, 32, 32), device='cuda')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             160\n",
            "         MaxPool2d-2           [-1, 16, 16, 16]               0\n",
            "            Conv2d-3           [-1, 32, 16, 16]           4,640\n",
            "         MaxPool2d-4             [-1, 32, 8, 8]               0\n",
            "            Linear-5                  [-1, 128]         262,272\n",
            "            Linear-6                   [-1, 64]           8,256\n",
            "            Linear-7                    [-1, 1]              65\n",
            "================================================================\n",
            "Total params: 275,393\n",
            "Trainable params: 275,393\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.24\n",
            "Params size (MB): 1.05\n",
            "Estimated Total Size (MB): 1.29\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cXmYTC3y_UD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V08JpIX8zBB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if use_cuda and torch.cuda.is_available():\n",
        "    net.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQBUHya_-QRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=1024\n",
        "import torch\n",
        "from torch.utils import data\n",
        "#import cudnn\n",
        "#from my_classes import Dataset\n",
        "\n",
        "\n",
        "# CUDA for PyTorch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "#cudnn.benchmark = True\n",
        "\n",
        "# Parameters\n",
        "params = {'batch_size': batch_size,\n",
        "          'shuffle': True,\n",
        "          }\n",
        "max_epochs = 100\n",
        "\n",
        "# Generators\n",
        "training_set = Dataset(X_train0, Y_train)\n",
        "training_generator = data.DataLoader(training_set, **params)\n",
        "\n",
        "validation_set = Dataset(X_valid0, Y_valid)\n",
        "validation_generator = data.DataLoader(validation_set, **params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITRqOqim59P2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKnnFnJZ1l4w",
        "colab_type": "code",
        "outputId": "1c43d475-acee-4880-808c-3c07bcb7d1c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "num_epochs=10\n",
        "correct=0\n",
        "total=0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(training_generator):   # Load a batch of images with its (index, data, class)\n",
        "        #images = Variable(images.view(-1, 28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
        "        #labels = Variable(labels)\n",
        "        \n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
        "        outputs = net(inputs)\n",
        "                                      # Forward pass: compute the output class given a image\n",
        "        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n",
        "        loss.backward()                                   # Backward pass: compute the weight\n",
        "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
        "        outputs[outputs>0.5]=1\n",
        "        outputs[outputs<0.5]=0\n",
        "        total += labels.shape[0]                    # Increment the total count\n",
        "        correct += (outputs == labels).sum()\n",
        "        if (i+1) % 100 == 0:                              # Logging\n",
        "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Accuracy: %.4f'\n",
        "                 %(epoch+1, num_epochs, i+1, len(X_train0)//batch_size, loss.item(), ((100 * correct.item() / total))))\n",
        "    #outputs = net(X_valid0.cuda())                             # Forward pass: compute the output class given a image\n",
        "    #loss = criterion(outputs, Y_valid.cuda())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [100/389], Loss: 0.5880, Accuracy: 72.3496\n",
            "Epoch [1/10], Step [200/389], Loss: 0.5885, Accuracy: 72.2695\n",
            "Epoch [1/10], Step [300/389], Loss: 0.5496, Accuracy: 72.4202\n",
            "Epoch [2/10], Step [100/389], Loss: 0.5557, Accuracy: 72.4920\n",
            "Epoch [2/10], Step [200/389], Loss: 0.5232, Accuracy: 72.4929\n",
            "Epoch [2/10], Step [300/389], Loss: 0.5393, Accuracy: 72.4763\n",
            "Epoch [3/10], Step [100/389], Loss: 0.5464, Accuracy: 72.4199\n",
            "Epoch [3/10], Step [200/389], Loss: 0.5709, Accuracy: 72.4400\n",
            "Epoch [3/10], Step [300/389], Loss: 0.5871, Accuracy: 72.4235\n",
            "Epoch [4/10], Step [100/389], Loss: 0.5619, Accuracy: 72.4482\n",
            "Epoch [4/10], Step [200/389], Loss: 0.5391, Accuracy: 72.4549\n",
            "Epoch [4/10], Step [300/389], Loss: 0.5510, Accuracy: 72.4521\n",
            "Epoch [5/10], Step [100/389], Loss: 0.5422, Accuracy: 72.4495\n",
            "Epoch [5/10], Step [200/389], Loss: 0.5580, Accuracy: 72.4501\n",
            "Epoch [5/10], Step [300/389], Loss: 0.5097, Accuracy: 72.4626\n",
            "Epoch [6/10], Step [100/389], Loss: 0.5450, Accuracy: 72.4890\n",
            "Epoch [6/10], Step [200/389], Loss: 0.5463, Accuracy: 72.4815\n",
            "Epoch [6/10], Step [300/389], Loss: 0.5445, Accuracy: 72.4870\n",
            "Epoch [7/10], Step [100/389], Loss: 0.5239, Accuracy: 72.5034\n",
            "Epoch [7/10], Step [200/389], Loss: 0.5342, Accuracy: 72.5117\n",
            "Epoch [7/10], Step [300/389], Loss: 0.5417, Accuracy: 72.5158\n",
            "Epoch [8/10], Step [100/389], Loss: 0.5691, Accuracy: 72.5185\n",
            "Epoch [8/10], Step [200/389], Loss: 0.5395, Accuracy: 72.5260\n",
            "Epoch [8/10], Step [300/389], Loss: 0.5453, Accuracy: 72.5287\n",
            "Epoch [9/10], Step [100/389], Loss: 0.5857, Accuracy: 72.5350\n",
            "Epoch [9/10], Step [200/389], Loss: 0.5544, Accuracy: 72.5408\n",
            "Epoch [9/10], Step [300/389], Loss: 0.5705, Accuracy: 72.5450\n",
            "Epoch [10/10], Step [100/389], Loss: 0.5496, Accuracy: 72.5438\n",
            "Epoch [10/10], Step [200/389], Loss: 0.5598, Accuracy: 72.5497\n",
            "Epoch [10/10], Step [300/389], Loss: 0.5621, Accuracy: 72.5559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaqXxlZrEmdh",
        "colab_type": "code",
        "outputId": "6091d1ca-093a-45c5-febb-ac314bd7afd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for inputs, labels in validation_generator:\n",
        "    #inputs = Variable(images.view(-1, 28*28))\n",
        "    \n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "    \n",
        "    \n",
        "    outputs = net(inputs)\n",
        "    outputs[outputs>0.5]=1\n",
        "    outputs[outputs<0.5]=0\n",
        "    total += labels.shape[0]                    # Increment the total count\n",
        "    correct += (outputs == labels).sum()     # Increment the correct count\n",
        "    \n",
        "print('Validation Accuracy of the network on the ' + str(total)+' test images: %.4f' % ((100 * correct.item() / total))+' correct: '+str((correct).item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 99600 test images: 72.2791 correct: 71990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tILwp5t-6CO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(net.state_dict(), 'pytorch1.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAQCOKtc6Sa5",
        "colab_type": "code",
        "outputId": "b88f2edb-36ee-478b-c6ef-e7d2cef9d735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load('pytorch1.pt'))\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "    net.cuda()\n",
        "net.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=2048, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcOkfctSL13n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
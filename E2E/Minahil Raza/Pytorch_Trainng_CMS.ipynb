{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_Trainng_CMS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-sKxH6Ud7-C",
        "colab_type": "text"
      },
      "source": [
        "#E2E Deep Learning Project Task (Pytorch)\n",
        "\n",
        "*  **Network used**: Convolutional Neural Network\n",
        "\n",
        "*  **Frameworks used:** \n",
        "Pytorch (for Training)\n",
        "Scikit-learn (for reporting, data splitting and measuring accuracy)\n",
        "\n",
        "*  **Environment used:** \n",
        "Google Colaboratory\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKHZ1hMKeLXa",
        "colab_type": "text"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_44iWke6PY3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn.functional import cross_entropy, nll_loss\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVKMqZQMeRih",
        "colab_type": "text"
      },
      "source": [
        "Setting the paths for the data to be retrieved.\n",
        "\n",
        "*You can change the variable \"pth\" according to your data path*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7DdMNn1Rkft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pth= '/content/drive/My Drive/task_GSoC/'   #enter your path here\n",
        "\n",
        "#Load dataset\n",
        "\n",
        "photon_data  = h5py.File(pth+'SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5')\n",
        "photon_X  = np.array(photon_data['X'])\n",
        "photon_Y  = np.array(photon_data['y'])\n",
        "\n",
        "electron_data= h5py.File(pth+'SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5')\n",
        "electron_X= np.array(electron_data['X'])\n",
        "electron_Y= np.array(electron_data['y'])\n",
        "\n",
        "X = np.transpose(np.concatenate((photon_X, electron_X)),(0, 3, 1 ,2)) #reshape data to torch format\n",
        "y = np.concatenate((photon_Y, electron_Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FeyY-OdUWcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#shuffle and train-val-test split\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.4)\n",
        "X_val, X_test, y_val, y_test= train_test_split(X_test, y_test, test_size= 0.5)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7Of5gnrwnrr",
        "colab_type": "code",
        "outputId": "f8a1c0ad-2e32-4206-be78-349fb640267f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(298800, 2, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVb0Sa8ues1q",
        "colab_type": "text"
      },
      "source": [
        "##Neural Network\n",
        "\n",
        "I used the following architecture for the neural network:\n",
        "\n",
        "\n",
        "*   2d Conv layer (8 3x3 filters with 'same' padding) \n",
        "*   2d Conv layer (16 3x3 filters with 'same' padding)\n",
        "*   2d Avg Pool layer (2x2 filter size)\n",
        "*   2d Conv layer (32 3x3 filters with 'same' padding)\n",
        "*   2d Conv layer (48 3x3 filters with 'same' padding)\n",
        "*   2d Avg Pool layer (2x2 filter size)\n",
        "*   2d Conv layer (54 3x3 filters with 'same' padding)\n",
        "*   2d Avg Pool layer (2x2 filter size)\n",
        "*   2d Conv layer (64 3x3 filters with 'same' padding)\n",
        "*   2d Avg Pool layer (2x2 filter size)\n",
        "*   Flatten layer\n",
        "*   Dense layer with 1024 outputs\n",
        "*   Dense layer with 512 outputs\n",
        "*   Dense layer with 64 outputs\n",
        "*   Dense layer with 32 outputs\n",
        "*   Output layer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOYffBk4RebG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(torch.nn.Module):\n",
        "    \n",
        "    #Our batch shape for input x is (2, 32, 32)\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        \n",
        "        self.conv1 = torch.nn.Conv2d(2, 8, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = torch.nn.Conv2d(32, 48, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv5 = torch.nn.Conv2d(48, 54, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv6 = torch.nn.Conv2d(54, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = torch.nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        \n",
        "        #4608 input features, 64 output features (see sizing flow below)\n",
        "        self.fc1 = torch.nn.Linear(2*2*64, 1024)\n",
        "        \n",
        "        #64 input features, 10 output features for our 10 defined classes\n",
        "        self.fc2 = torch.nn.Linear(1024, 512)\n",
        "        self.fc3 = torch.nn.Linear(512, 64)\n",
        "        self.fc4 = torch.nn.Linear(64, 32)\n",
        "        self.fc5 = torch.nn.Linear(32, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv6(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = torch.flatten(x,1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = torch.sigmoid(self.fc5(x))\n",
        "        return(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtrvEx7OgaNV",
        "colab_type": "text"
      },
      "source": [
        "**Making a torch Dataset class and generating dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9vlnhkUnD9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#class for the dataset\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, target):\n",
        "        self.data = torch.from_numpy(data).float()\n",
        "        self.target = torch.from_numpy(target).float()\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "#batch size\n",
        "bs = 512\n",
        "\n",
        "#Training Data\n",
        "train_data = MyDataset(X_train, y_train)\n",
        "train_loader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size = bs,\n",
        "    shuffle = True,\n",
        ")\n",
        "\n",
        "#Validation Data\n",
        "val_data = MyDataset(X_val, y_val)\n",
        "val_loader = DataLoader(\n",
        "    val_data,\n",
        "    batch_size = bs,\n",
        "    shuffle = True,\n",
        ")\n",
        "\n",
        "#Test Data\n",
        "test_data = MyDataset(X_test, y_test)\n",
        "test_loader = DataLoader(\n",
        "    test_data,\n",
        "    batch_size = bs,\n",
        "    shuffle = True,\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U3-ZQ_HYjOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining the model\n",
        "model = CNN()\n",
        "model.cuda()\n",
        "# defining the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "# defining the loss function\n",
        "criterion = torch.nn.BCELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8Ycnqda_XKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# epoch to start from\n",
        "epochs = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkqcF-UchuI6",
        "colab_type": "text"
      },
      "source": [
        "Run this block in order to load a pre trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKb7vW7W9vSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#change the name of the .pth file as per requirement\n",
        "checkpoint = torch.load(pth+\"epoch_249.pth\")\n",
        "model.load_state_dict(checkpoint['model'])\n",
        "epochs = checkpoint['epoch']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEqJSPF7iNvq",
        "colab_type": "text"
      },
      "source": [
        "**The Training Function**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cGWPqvKRfTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch):\n",
        "    # to put the model in training mode\n",
        "    model.train()\n",
        "    tr_acc = 0\n",
        "    tr_loss = 0\n",
        "\n",
        "    #lists to save the progress\n",
        "    train_accuracies=[]\n",
        "    train_losses=[]\n",
        "    val_accuracies=[]\n",
        "    \n",
        "    for tr_batch_id, (tr_data, tr_target) in enumerate(train_loader):\n",
        "      tr_data = tr_data.to('cuda')\n",
        "      tr_target = tr_target.to('cuda')\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      tr_preds = model(tr_data)\n",
        "      loss = criterion(tr_preds, tr_target)\n",
        "      tr_loss += loss\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      #calculating accuracy using sklearn\n",
        "      binary_preds = (tr_preds>0.5).type(torch.FloatTensor)\n",
        "      acc = accuracy_score(tr_target.cpu(),binary_preds.cpu())\n",
        "      tr_acc += acc\n",
        "\n",
        "      ###### uncomment this to view mini batch progress ######\n",
        "      # if tr_batch_id % 75 == 0:\n",
        "      #   print(\"Batch # {:>3} : Loss = {}\".format(tr_batch_id,loss.item()))\n",
        "      \n",
        "    tr_acc = 100*(tr_acc / (tr_batch_id+1))\n",
        "    tr_loss = tr_loss / (tr_batch_id+1)\n",
        "\n",
        "    # to put the model in evaluation mode\n",
        "    model.eval() # set model in inference mode (need this because of dropout)\n",
        "    val_acc = 0\n",
        "    \n",
        "    for val_batch_id, (val_data, val_target) in enumerate(val_loader):\n",
        "        val_data = val_data.to('cuda')\n",
        "        val_target = val_target.to('cuda')\n",
        "\n",
        "        val_preds = model(val_data)\n",
        "        binary_preds = (val_preds>0.5).type(torch.FloatTensor)\n",
        "\n",
        "        acc = accuracy_score(val_target.cpu(), binary_preds.cpu())\n",
        "        val_acc += acc\n",
        "\n",
        "    val_acc = 100*(val_acc / (val_batch_id+1))\n",
        "\n",
        "    train_accuracies.append(tr_acc)\n",
        "    val_accuracies.append(val_acc)\n",
        "    train_losses.append(tr_loss)\n",
        "\n",
        "    print('Epoch: {}  Train_Loss: ({:.5f})  Train_Accuracy: ({:.3f}%)  Validation_Accuracy: ({:.3f}%)'.format(epoch+1,tr_loss, tr_acc, val_acc))\n",
        "    # return preds,target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l11j7AbwZFBQ",
        "colab_type": "code",
        "outputId": "4656b840-eace-4ad6-d24f-87b0c1125e02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# defining the number of epochs\n",
        "n_epochs = 255\n",
        "\n",
        "for epoch in range(epochs,n_epochs):\n",
        "    train(epoch)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250  Train_Loss: (0.53787)  Train_Accuracy: (73.465%)  Validation_Accuracy: (73.687%)\n",
            "Epoch: 251  Train_Loss: (0.53797)  Train_Accuracy: (73.462%)  Validation_Accuracy: (73.780%)\n",
            "Epoch: 252  Train_Loss: (0.53706)  Train_Accuracy: (73.575%)  Validation_Accuracy: (73.873%)\n",
            "Epoch: 253  Train_Loss: (0.53708)  Train_Accuracy: (73.495%)  Validation_Accuracy: (73.801%)\n",
            "Epoch: 254  Train_Loss: (0.53672)  Train_Accuracy: (73.562%)  Validation_Accuracy: (73.810%)\n",
            "Epoch: 255  Train_Loss: (0.53689)  Train_Accuracy: (73.533%)  Validation_Accuracy: (73.819%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAc6N6ZxjIn0",
        "colab_type": "text"
      },
      "source": [
        "**Saving the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FngnSpNjw4Nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state = {'model': model.state_dict(),\n",
        "         'epoch': epoch}\n",
        "torch.save(state,pth+'epoch_'+str(epoch)+'.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlwqXRFpj99H",
        "colab_type": "text"
      },
      "source": [
        "**Testing the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqrrpZEhdkIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "  model.eval()\n",
        "  test_acc=0\n",
        "\n",
        "  for test_batch_id, (test_data, test_target) in enumerate(test_loader):\n",
        "        test_data = test_data.to('cuda')\n",
        "        test_target = test_target.to('cuda')\n",
        "\n",
        "        test_preds = model(test_data)\n",
        "        binary_preds = (test_preds>0.5).type(torch.FloatTensor)\n",
        "\n",
        "        acc = accuracy_score(test_target.cpu(), binary_preds.cpu())\n",
        "        test_acc += acc\n",
        "\n",
        "  test_acc = 100*(test_acc / (test_batch_id+1))\n",
        "  \n",
        "  print('Test_Accuracy: ({:.3f}%)'.format(test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnKj60bfjeB7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4baf3875-96db-485e-9043-a2e0902c91e3"
      },
      "source": [
        "test()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test_Accuracy: (73.494%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
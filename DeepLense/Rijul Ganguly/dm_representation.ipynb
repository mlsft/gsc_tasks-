{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dm_representation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBRx5J5vcHzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tarfile\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5ld7MKRcgUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fname = \"lenses.tgz\"\n",
        "tar = tarfile.open(fname, \"r:gz\")\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBz7Mpd-dHbY",
        "colab_type": "code",
        "outputId": "51dc89e8-2057-4701-8caf-b0e94822e05a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd lenses"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/lenses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNwOdCnkdd2U",
        "colab_type": "code",
        "outputId": "e716b8af-f20f-4493-cc2b-1e3cb36217f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[34;42mno_sub\u001b[0m/  \u001b[34;42msub\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYpAUYbN85vl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu6cTmqCdiRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_img = []\n",
        "for img in glob.glob(\"sub/*.jpg\"):\n",
        "    n = cv2.imread(img)\n",
        "    sub_img.append(n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtvLAjXk8VsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_sub_img = []\n",
        "for img in glob.glob(\"no_sub/*.jpg\"):\n",
        "    n = cv2.imread(img)\n",
        "    no_sub_img.append(n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e9MbcUa8Wuj",
        "colab_type": "code",
        "outputId": "7d906386-5187-4d61-dfba-c96303d694dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(no_sub_img)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxcINQuX-QFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "overall_dataset = []\n",
        "for i in sub_img:\n",
        "    overall_dataset.append((i,0))\n",
        "\n",
        "for i in no_sub_img:\n",
        "    overall_dataset.append((i,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW7GvL86CBU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.shuffle(overall_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmFQj8AxCD7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = [i[0] for i in overall_dataset]\n",
        "labels = [i[1] for i in overall_dataset]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu6Hx1vxCVPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = data[:7500]\n",
        "train_labels = labels[:7500]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-FaefSwC-nz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = data[7500:]\n",
        "test_labels = labels[7500:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFdl9iVPDSFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net,self).__init__()\n",
        "\n",
        "        self.c1 = nn.Sequential(\n",
        "                    nn.Conv2d(3,6,5),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    nn.BatchNorm2d(6)\n",
        "        )\n",
        "\n",
        "        self.c2 = nn.Sequential(\n",
        "                   nn.MaxPool2d(2,2),\n",
        "                   nn.Conv2d(6,16,5),\n",
        "                   nn.ReLU(inplace=True),\n",
        "                   nn.BatchNorm2d(16) \n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "                    nn.Linear(76176, 1200),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    nn.Linear(1200,200),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    nn.Linear(200,2)\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.c1(x)\n",
        "        x = self.c2(x)\n",
        "        x = x.view(-1,76176)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzHTxDw3Gsrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Net().cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBLUoe11M1kk",
        "colab_type": "text"
      },
      "source": [
        "#TRAINING TIME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVw22GnSJ9l3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr = 0.0001, momentum = 0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD9wl4qsKOX1",
        "colab_type": "code",
        "outputId": "75825275-673e-4043-d6ec-9869b404a78a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(5):\n",
        "    for d in range(75):\n",
        "        batch_train_data_curr = torch.from_numpy(np.array(train_data[d*100:d*100+100]).reshape(-1,3,150,150)).type(torch.FloatTensor).cuda()\n",
        "        batch_train_label_curr = torch.from_numpy(np.array(train_labels[d*100:d*100+100])).type(torch.LongTensor).cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(batch_train_data_curr)\n",
        "\n",
        "        loss = criterion(outputs, batch_train_label_curr)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if(d%10 == 0):\n",
        "            print(\"EPOCH IS {}\\n AND CURRENT LOSS IS {}/n\".format(epoch, loss.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH IS 0\n",
            " AND CURRENT LOSS IS 0.6906511187553406/n\n",
            "EPOCH IS 0\n",
            " AND CURRENT LOSS IS 0.6920977830886841/n\n",
            "EPOCH IS 0\n",
            " AND CURRENT LOSS IS 0.6963557600975037/n\n",
            "EPOCH IS 0\n",
            " AND CURRENT LOSS IS 0.6675735712051392/n\n",
            "EPOCH IS 0\n",
            " AND CURRENT LOSS IS 0.6556903123855591/n\n",
            "EPOCH IS 0\n",
            " AND CURRENT LOSS IS 0.6457473635673523/n\n",
            "EPOCH IS 0\n",
            " AND CURRENT LOSS IS 0.6644276976585388/n\n",
            "EPOCH IS 0\n",
            " AND CURRENT LOSS IS 0.6487205028533936/n\n",
            "EPOCH IS 1\n",
            " AND CURRENT LOSS IS 0.6603279709815979/n\n",
            "EPOCH IS 1\n",
            " AND CURRENT LOSS IS 0.6323608160018921/n\n",
            "EPOCH IS 1\n",
            " AND CURRENT LOSS IS 0.6480584740638733/n\n",
            "EPOCH IS 1\n",
            " AND CURRENT LOSS IS 0.6064150929450989/n\n",
            "EPOCH IS 1\n",
            " AND CURRENT LOSS IS 0.6085724830627441/n\n",
            "EPOCH IS 1\n",
            " AND CURRENT LOSS IS 0.5798658132553101/n\n",
            "EPOCH IS 1\n",
            " AND CURRENT LOSS IS 0.6136316061019897/n\n",
            "EPOCH IS 1\n",
            " AND CURRENT LOSS IS 0.5978912711143494/n\n",
            "EPOCH IS 2\n",
            " AND CURRENT LOSS IS 0.6038119792938232/n\n",
            "EPOCH IS 2\n",
            " AND CURRENT LOSS IS 0.5746724605560303/n\n",
            "EPOCH IS 2\n",
            " AND CURRENT LOSS IS 0.5900063514709473/n\n",
            "EPOCH IS 2\n",
            " AND CURRENT LOSS IS 0.5490365624427795/n\n",
            "EPOCH IS 2\n",
            " AND CURRENT LOSS IS 0.5643484592437744/n\n",
            "EPOCH IS 2\n",
            " AND CURRENT LOSS IS 0.5154937505722046/n\n",
            "EPOCH IS 2\n",
            " AND CURRENT LOSS IS 0.5679173469543457/n\n",
            "EPOCH IS 2\n",
            " AND CURRENT LOSS IS 0.5526269674301147/n\n",
            "EPOCH IS 3\n",
            " AND CURRENT LOSS IS 0.548134982585907/n\n",
            "EPOCH IS 3\n",
            " AND CURRENT LOSS IS 0.5218045115470886/n\n",
            "EPOCH IS 3\n",
            " AND CURRENT LOSS IS 0.540107011795044/n\n",
            "EPOCH IS 3\n",
            " AND CURRENT LOSS IS 0.5033875107765198/n\n",
            "EPOCH IS 3\n",
            " AND CURRENT LOSS IS 0.5211240649223328/n\n",
            "EPOCH IS 3\n",
            " AND CURRENT LOSS IS 0.46277034282684326/n\n",
            "EPOCH IS 3\n",
            " AND CURRENT LOSS IS 0.5305435657501221/n\n",
            "EPOCH IS 3\n",
            " AND CURRENT LOSS IS 0.5126625299453735/n\n",
            "EPOCH IS 4\n",
            " AND CURRENT LOSS IS 0.5003378391265869/n\n",
            "EPOCH IS 4\n",
            " AND CURRENT LOSS IS 0.4767191708087921/n\n",
            "EPOCH IS 4\n",
            " AND CURRENT LOSS IS 0.4966847896575928/n\n",
            "EPOCH IS 4\n",
            " AND CURRENT LOSS IS 0.46622979640960693/n\n",
            "EPOCH IS 4\n",
            " AND CURRENT LOSS IS 0.48364371061325073/n\n",
            "EPOCH IS 4\n",
            " AND CURRENT LOSS IS 0.42012089490890503/n\n",
            "EPOCH IS 4\n",
            " AND CURRENT LOSS IS 0.49792420864105225/n\n",
            "EPOCH IS 4\n",
            " AND CURRENT LOSS IS 0.47785335779190063/n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI0REl5GTsUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = 0\n",
        "for z,i in enumerate(test_data):\n",
        "    j = torch.from_numpy(i.reshape(-1,3,150,150)).type(torch.FloatTensor).cuda()\n",
        "    a = net(j)\n",
        "    _,b = torch.max(a,1)\n",
        "    if(b.item()==test_labels[z]):\n",
        "        count +=1\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEugZWisUetG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count /= 2500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru7nQkI_WFdu",
        "colab_type": "code",
        "outputId": "1a50202c-f391-42ff-84ba-499636097436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7132"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaW1xqaxWGvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}